{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56bfb0c4-db0a-4131-a49f-ac745d113ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leyendo imagenes de  C:\\Users\\Usuario iTC\\Terry\\train\\\n",
      "C:\\Users\\Usuario iTC\\Terry\\train\\CLASS_02 1\n",
      "C:\\Users\\Usuario iTC\\Terry\\train\\CLASS_03 62\n",
      "C:\\Users\\Usuario iTC\\Terry\\train\\CLASS_04 213\n",
      "C:\\Users\\Usuario iTC\\Terry\\train\\CLASS_05 105\n",
      "C:\\Users\\Usuario iTC\\Terry\\train\\CLASS_06 949\n",
      "C:\\Users\\Usuario iTC\\Terry\\train\\CLASS_07 37\n",
      "C:\\Users\\Usuario iTC\\Terry\\train\\CLASS_08 204\n",
      "Directorios leidos: 7\n",
      "Imagenes en cada directorio [63, 213, 105, 949, 37, 204, 62]\n",
      "suma Total de imagenes en subdirs: 1633\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "dirname = os.path.join(os.getcwd(), 'train')\n",
    "imgpath = dirname + os.sep \n",
    "\n",
    "images = []\n",
    "directories = []\n",
    "dircount = []\n",
    "prevRoot=''\n",
    "cant=0\n",
    "\n",
    "print(\"leyendo imagenes de \",imgpath)\n",
    "\n",
    "for root, dirnames, filenames in os.walk(imgpath):\n",
    "    for filename in filenames:\n",
    "        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
    "            cant=cant+1\n",
    "            filepath = os.path.join(root, filename)\n",
    "            image = plt.imread(filepath)\n",
    "            images.append(image)\n",
    "            b = \"Leyendo...\" + str(cant)\n",
    "            print (b, end=\"\\r\")\n",
    "            if prevRoot !=root:\n",
    "                print(root, cant)\n",
    "                prevRoot=root\n",
    "                directories.append(root)\n",
    "                dircount.append(cant)\n",
    "                cant=0\n",
    "dircount.append(cant)\n",
    "\n",
    "dircount = dircount[1:]\n",
    "dircount[0]=dircount[0]+1\n",
    "print('Directorios leidos:',len(directories))\n",
    "print(\"Imagenes en cada directorio\", dircount)\n",
    "print('suma Total de imagenes en subdirs:',sum(dircount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5068bdbe-5b92-4786-9617-29fa1faf7fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad etiquetas creadas:  1633\n"
     ]
    }
   ],
   "source": [
    "labels=[]\n",
    "indice=0\n",
    "for cantidad in dircount:\n",
    "    for i in range(cantidad):\n",
    "        labels.append(indice)\n",
    "    indice=indice+1\n",
    "print(\"Cantidad etiquetas creadas: \",len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea26c596-615c-4a9f-b1ec-2b2cbefeecc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 CLASS_02\n",
      "1 CLASS_03\n",
      "2 CLASS_04\n",
      "3 CLASS_05\n",
      "4 CLASS_06\n",
      "5 CLASS_07\n",
      "6 CLASS_08\n"
     ]
    }
   ],
   "source": [
    "carnes=[]\n",
    "indice=0\n",
    "for directorio in directories:\n",
    "    name = directorio.split(os.sep)\n",
    "    print(indice , name[len(name)-1])\n",
    "    carnes.append(name[len(name)-1])\n",
    "    indice=indice+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae26a359-2b62-41ad-a691-aff91ac61d43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outputs :  7\n",
      "Output classes :  [0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y = np.array(labels)\n",
    "X = np.array(images, dtype=np.uint8) #convierto de lista a numpy\n",
    "# Find the unique numbers from the train labels\n",
    "classes = np.unique(y)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b2b26ef-729d-4f70-9a36-30fb32118862",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (1306, 21, 28, 3) (1306,)\n",
      "Testing data shape :  (327, 21, 28, 3) (327,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "train_X,test_X,train_Y,test_Y = train_test_split(X,y,test_size=0.2)\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ', test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "819175ca-9bef-43dc-aec1-94dd29df1e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "#plt.subplot(121)\n",
    "#plt.imshow(train_X[0,:,:], cmap='gray')\n",
    "#plt.title(\"Ground Truth : {}\".format(train_Y[0]))\n",
    "\n",
    "# Display the first image in testing data\n",
    "#plt.subplot(122)\n",
    "#plt.imshow(test_X[0,:,:], cmap='gray')\n",
    "#plt.title(\"Ground Truth : {}\".format(test_Y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dd1922c-7021-4790-825a-0f094687375c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "train_X = train_X / 255.\n",
    "test_X = test_X / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0caf1188-f0b5-486f-8ec8-92c4bfdc13d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: 1\n",
      "After conversion to one-hot: [0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "# Change the labels from categorical to one-hot encoding\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    "\n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label:', train_Y[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2302533-1d01-4e15-ad28-74d088930eba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Mezclar todo y crear los grupos de entrenamiento y testing\n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac42bf7a-896a-4b2d-bcea-b7c1ce7e7f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044, 21, 28, 3) (262, 21, 28, 3) (1044, 7) (262, 7)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape,valid_X.shape,train_label.shape,valid_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7991f30c-1370-4c68-85bd-c0df5761ba7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#declaramos variables con los parámetros de configuración de la red\n",
    "INIT_LR = 1e-3 # Valor inicial de learning rate. El valor 1e-3 corresponde con 0.001\n",
    "epochs = 6 # Cantidad de iteraciones completas al conjunto de imagenes de entrenamiento\n",
    "batch_size = 100 # cantidad de imágenes que se toman a la vez en memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3fa277d-d3e6-4b2e-9b9d-1b86c8e86870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.activation import LeakyReLU\n",
    "carnes_model = Sequential()\n",
    "carnes_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(21,28,3)))\n",
    "carnes_model.add(LeakyReLU(alpha=0.1))\n",
    "carnes_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "carnes_model.add(Dropout(0.5))\n",
    "\n",
    "carnes_model.add(Flatten())\n",
    "carnes_model.add(Dense(32, activation='linear'))\n",
    "carnes_model.add(LeakyReLU(alpha=0.1))\n",
    "carnes_model.add(Dropout(0.5))\n",
    "carnes_model.add(Dense(nClasses, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74aa89d1-7e29-4256-8994-6e1e6f0f9be1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 21, 28, 32)        896       \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 21, 28, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 11, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 11, 14, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4928)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                157728    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 158,855\n",
      "Trainable params: 158,855\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "carnes_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22ef0ed9-206e-4ab8-8ec6-145d606657f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "carnes_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adagrad(learning_rate=INIT_LR, decay=INIT_LR / 100),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e48c4686-c8c4-4f37-9d21-0d48bb61f7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "11/11 [==============================] - 1s 35ms/step - loss: 1.9405 - accuracy: 0.5316 - val_loss: 1.9334 - val_accuracy: 0.5954\n",
      "Epoch 2/6\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.9305 - accuracy: 0.5805 - val_loss: 1.9244 - val_accuracy: 0.5954\n",
      "Epoch 3/6\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.9224 - accuracy: 0.5776 - val_loss: 1.9166 - val_accuracy: 0.5954\n",
      "Epoch 4/6\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 1.9149 - accuracy: 0.5785 - val_loss: 1.9092 - val_accuracy: 0.5954\n",
      "Epoch 5/6\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.9096 - accuracy: 0.5785 - val_loss: 1.9025 - val_accuracy: 0.5954\n",
      "Epoch 6/6\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.9029 - accuracy: 0.5785 - val_loss: 1.8958 - val_accuracy: 0.5954\n"
     ]
    }
   ],
   "source": [
    "# este paso puede tomar varios minutos, dependiendo de tu ordenador, cpu y memoria ram libre\n",
    "# como ejemplo, en mi Macbook pro tarda 4 minutos\n",
    "carnes_train = carnes_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83a1982c-57cd-414e-994a-24de4029f774",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: carnes_mnist.h5py\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: carnes_mnist.h5py\\assets\n"
     ]
    }
   ],
   "source": [
    "# guardamos la red, para reutilizarla en el futuro, sin tener que volver a entrenar\n",
    "carnes_model.save(\"carnes_mnist.h5py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47b674cf-1006-48e8-8dc4-1d092465ae78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.8984 - accuracy: 0.5719\n"
     ]
    }
   ],
   "source": [
    "test_eval = carnes_model.evaluate(test_X, test_Y_one_hot, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9dcec31-c356-4a5e-be74-be6153b5f69c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.8984278440475464\n",
      "Test accuracy: 0.571865439414978\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75abd7bb-eb16-49d7-b3a1-969134fdad8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted_classes2 = carnes_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0395a9c2-8964-44c8-83a4-05c5888ef0bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_classes=[]\n",
    "for predicted_carnes in predicted_classes2:\n",
    "    predicted_classes.append(predicted_carnes.tolist().index(max(predicted_carnes)))\n",
    "predicted_classes=np.array(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16258c40-66f0-4269-8ca9-7cbbf346fc19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((327,), (327,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec5bee95-f548-4375-9c20-1a0b68d1cf7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.00      0.00      0.00        12\n",
      "     Class 1       0.00      0.00      0.00        46\n",
      "     Class 2       0.00      0.00      0.00        19\n",
      "     Class 3       0.57      1.00      0.73       187\n",
      "     Class 4       0.00      0.00      0.00         6\n",
      "     Class 5       0.00      0.00      0.00        45\n",
      "     Class 6       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.57       327\n",
      "   macro avg       0.08      0.14      0.10       327\n",
      "weighted avg       0.33      0.57      0.42       327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = [\"Class {}\".format(i) for i in range(nClasses)]\n",
    "print(classification_report(test_Y, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "455545a3-c2e5-4bac-aa4a-0f5b94693e5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "test/clase3.png CLASS_05\n"
     ]
    }
   ],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "images=[]\n",
    "# AQUI ESPECIFICAMOS UNAS IMAGENES\n",
    "filenames = ['test/clase3.png']\n",
    "\n",
    "for filepath in filenames:\n",
    "    image = plt.imread(filepath,0)\n",
    "    image_resized = resize(image, (21, 28),anti_aliasing=True,clip=False,preserve_range=True)\n",
    "    images.append(image_resized)\n",
    "\n",
    "X = np.array(images, dtype=np.uint8) #convierto de lista a numpy\n",
    "test_X = X.astype('float32')\n",
    "test_X = test_X / 255.\n",
    "\n",
    "predicted_classes = carnes_model.predict(test_X)\n",
    "\n",
    "for i, img_tagged in enumerate(predicted_classes):\n",
    "    print(filenames[i], carnes[img_tagged.tolist().index(max(img_tagged))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4c370-55eb-4531-9477-b641557249b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
